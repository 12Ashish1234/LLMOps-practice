{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langsmith import Client\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary configs for Azure OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_configs = {\n",
    "    \"base_url\": \"https://channel-openai-org.openai.azure.com/\",\n",
    "    \"model_deployment\": \"GPT-Channel-OpenAI\",\n",
    "    \"model_name\": \"gpt-35-turbo\",\n",
    "    \"embedding_deployment\": \"GPT-Channel-OpenAI\",\n",
    "    \"embedding_name\": \"AIEmbeddings\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting of Environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT_2\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model: str = \"gpt-35-turbo\"\n",
    "deployment_name = \"GPT-Channel-OpenAI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating object of the Large Language Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"model_deployment\"],\n",
    "    model=azure_configs[\"model_name\"],\n",
    "    validate_base_url=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The client that is required for Langsmith trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart on Langsmith feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI language model, I don't have personal opinions or beliefs. However, I can provide a possible scenario based on scientific knowledge and predictions.\\n\\nIf humans start settling on Mars, it will likely have a significant impact on the planet Earth. Initially, it may lead to a decrease in the population density and resource consumption on Earth, which may positively impact the environment.\\n\\nOn the other hand, settling on Mars will require a considerable amount of resources, including energy, water, and food, which may lead to increased resource consumption on Earth to support the Mars settlement. There may also be significant technological advancements made to support the settlement, which could have both positive and negative impacts on the environment.\\n\\nAdditionally, the exploration and colonization of Mars may lead to the discovery of new scientific knowledge and resources that could benefit Earth. However, it may also lead to the exploitation of Mars' resources and potential ecological destruction of the planet.\\n\\nOverall, the impact of humans settling on Mars on Earth is complex and unknown. It will likely involve a balance of environmental, technological, and ethical considerations to ensure a positive outcome for both planets.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\n",
    "    \"Hypothetically, what do you think will happen to earth once humans start settling in mars?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Quick Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset (only Inputs, No output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "[Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\My Learnings\\Langsmith\\env\\Lib\\site-packages\\langsmith\\utils.py:111\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\My Learnings\\Langsmith\\env\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRap Battle Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Storing inputs in a dataset lets us\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# run chains and LLMs over a shared set of examples.\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRap battle prompts.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_prompt \u001b[38;5;129;01min\u001b[39;00m example_inputs:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Each example must be unique and have inputs defined.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Outputs are optional\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     client\u001b[38;5;241m.\u001b[39mcreate_example(\n\u001b[0;32m     21\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_prompt},\n\u001b[0;32m     22\u001b[0m         outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m         dataset_id\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m     24\u001b[0m     )\n",
      "File \u001b[1;32md:\\My Learnings\\Langsmith\\env\\Lib\\site-packages\\langsmith\\client.py:2335\u001b[0m, in \u001b[0;36mClient.create_dataset\u001b[1;34m(self, dataset_name, description, data_type)\u001b[0m\n\u001b[0;32m   2325\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ls_schemas\u001b[38;5;241m.\u001b[39mDatasetCreate(\n\u001b[0;32m   2326\u001b[0m     name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[0;32m   2327\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[0;32m   2328\u001b[0m     data_type\u001b[38;5;241m=\u001b[39mdata_type,\n\u001b[0;32m   2329\u001b[0m )\n\u001b[0;32m   2330\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m   2331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2332\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_headers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m   2333\u001b[0m     data\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[0;32m   2334\u001b[0m )\n\u001b[1;32m-> 2335\u001b[0m \u001b[43mls_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[0;32m   2337\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[0;32m   2338\u001b[0m     _host_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host_url,\n\u001b[0;32m   2339\u001b[0m     _tenant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_optional_tenant_id(),\n\u001b[0;32m   2340\u001b[0m )\n",
      "File \u001b[1;32md:\\My Learnings\\Langsmith\\env\\Lib\\site-packages\\langsmith\\utils.py:113\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    111\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHTTPError\u001b[0m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}"
     ]
    }
   ],
   "source": [
    "example_inputs = [\n",
    "    \"a rap battle between Atticus Finch and Cicero\",\n",
    "    \"a rap battle between Barbie and Oppenheimer\",\n",
    "    \"a Pythonic rap battle between two swallows: one European and one African\",\n",
    "    \"a rap battle between Aubrey Plaza and Stephen Colbert\",\n",
    "]\n",
    "\n",
    "dataset_name = \"Rap Battle Dataset\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Rap battle prompts.\",\n",
    ")\n",
    "\n",
    "for input_prompt in example_inputs:\n",
    "    # Each example must be unique and have inputs defined.\n",
    "    # Outputs are optional\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs=None,\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate datasets with LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'diligent-chicken-30' at:\n",
      "https://smith.langchain.com/o/d8d276bd-e36b-55d0-b03a-1ccc6277cbef/datasets/dd500565-01a0-405a-8631-4bf8f5bb7b50/compare?selectedSessions=d1f783c1-4336-41c4-9218-1055e8d066a7\n",
      "\n",
      "View all tests for Dataset Rap Battle Dataset at:\n",
      "https://smith.langchain.com/o/d8d276bd-e36b-55d0-b03a-1ccc6277cbef/datasets/dd500565-01a0-405a-8631-4bf8f5bb7b50\n",
      "[>                                                 ] 0/4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM failed for example acd1f7d1-efe5-4e4e-beae-28784bcfc5a1 with inputs {'question': 'a rap battle between Barbie and Oppenheimer'}\n",
      "Error Type: ValueError, Message: Azure has not provided the response due to a content filter being triggered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 4/4"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_name': 'diligent-chicken-30',\n",
       " 'results': {'14c1b691-ae2b-4391-91e2-5138b5d5f1e0': {'input': {'question': 'a rap battle between Aubrey Plaza and Stephen Colbert'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=None, value=None, comment=\"Error evaluating run e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='harmfulness', score=None, value=None, comment=\"Error evaluating run e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='misogyny', score=None, value=None, comment=\"Error evaluating run e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='cliche', score=None, value=None, comment=\"Error evaluating run e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 9.886562,\n",
       "   'run_id': 'e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c',\n",
       "   'output': AIMessage(content=\"Verse 1: Aubrey Plaza\\n\\nI'm Aubrey Plaza, the queen of deadpan\\nYou're Stephen Colbert, but you ain't no man\\nI'm here to battle and show you what's what\\nSo sit back, relax, and watch me strut\\n\\nVerse 2: Stephen Colbert\\n\\nI'm Stephen Colbert, the king of late night\\nYou're Aubrey Plaza, but you ain't got the might\\nI'm here to school you and show you the way\\nSo listen up, Aubrey, and don't you stray\\n\\nVerse 3: Aubrey Plaza\\n\\nYou think you're tough, but you ain't got the skills\\nI'm the queen of comedy, I pay the bills\\nYou're just a talk show host, with a mic in your hand\\nBut when it comes to rapping, you're just a also-ran\\n\\nVerse 4: Stephen Colbert\\n\\nI'm not just a talk show host, I'm a master of wit\\nYou're just a one-trick pony, and that's all you'll ever get\\nI'll take you down, with my rhymes so sublime\\nSo sit back, Aubrey, and watch me shine\\n\\nVerse 5: Aubrey Plaza\\n\\nYou talk a big game, but you can't back it up\\nI'll take you on, and leave you in the dust\\nI'll make you laugh, with my quick wit and charm\\nAnd when it's all over, you'll be sounding the alarm\\n\\nVerse 6: Stephen Colbert\\n\\nYou may be funny, but you're no match for me\\nI'll take you down, and make you see\\nThat when it comes to rapping, I'm the king\\nAnd you, Aubrey Plaza, are just a thing\\n\\nVerse 7: Aubrey Plaza\\n\\nYou think you're the king, but you're just a joke\\nI'll take you down, with my rhymes so dope\\nI'll leave you in the dust, and make you see\\nThat when it comes to rapping, I'm the MVP\\n\\nVerse 8: Stephen Colbert\\n\\nYou talk a big game, but you're just a pretender\\nI'll take you down, with my rhymes so tender\\nYou may be funny, but you're no match for me\\nSo bow down, Aubrey Plaza, and concede\\n\\nVerse 9: Aubrey Plaza\\n\\nI won't bow down, I'll stand my ground\\nI'll take you on, and leave you astound\\nI'll make you laugh, with my quick wit and charm\\nAnd when it's all over, you'll be sounding the alarm\\n\\nVerse 10: Stephen Colbert\\n\\nYou may have won, but I'll be back\\nI'll take you down, with my rhymes so whack\\nYou may be funny, but you're no match for me\\nSo watch out, Aubrey Plaza, and let me be.\", response_metadata={'token_usage': {'completion_tokens': 597, 'prompt_tokens': 18, 'total_tokens': 615}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-e3dbe4b5-613c-4436-8eb3-8fc13ace3f0c-0')},\n",
       "  '39db9972-6655-438d-af77-e23e395cbbff': {'input': {'question': 'a Pythonic rap battle between two swallows: one European and one African'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=None, value=None, comment=\"Error evaluating run 3d9ac9b4-456c-4391-bc04-6c7e77e09c70: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='harmfulness', score=None, value=None, comment=\"Error evaluating run 3d9ac9b4-456c-4391-bc04-6c7e77e09c70: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='misogyny', score=None, value=None, comment=\"Error evaluating run 3d9ac9b4-456c-4391-bc04-6c7e77e09c70: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='cliche', score=None, value=None, comment=\"Error evaluating run 3d9ac9b4-456c-4391-bc04-6c7e77e09c70: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 6.109395,\n",
       "   'run_id': '3d9ac9b4-456c-4391-bc04-6c7e77e09c70',\n",
       "   'output': AIMessage(content=\"European Swallow:\\nYo, listen up, I'm the European swallow\\nFlying high, never low, always on the go\\nI migrate across the continent, no need for a passport\\nI'm the fastest and the strongest, there's no contest\\n\\nAfrican Swallow:\\nHold up, hold up, don't get too ahead\\nI'm the African swallow, and I'm not easily led\\nI may be small, but I'm swift and agile\\nI fly across the savannah, with grace and style\\n\\nEuropean Swallow:\\nYou may be fast, but I'm the king of the sky\\nMy wings are strong, and my flight is high\\nI swoop and dive, with precision and skill\\nYou can't match my moves, I'm too much to kill\\n\\nAfrican Swallow:\\nDon't be too quick to boast, you European bird\\nI may not be as big, but I have a sharp word\\nI'm a master of the air, with a keen sense of sight\\nI swoop and dive, with all my might\\n\\nEuropean Swallow:\\nYou may have some skills, but you can't match my speed\\nMy wings are strong, and my flight is indeed\\nI'm the European swallow, and I reign supreme\\nYou can't touch me, I'm the ultimate flying machine\\n\\nAfrican Swallow:\\nYou may be fast, but I have a heart of gold\\nI fly with grace and beauty, never to be sold\\nI'm the African swallow, and I'm proud of my heritage\\nI'll fly circles around you, with my wings and courage\\n\\nEuropean Swallow:\\nWell, it seems we both have our strengths and skills\\nWe may be different, but we both have the will\\nTo fly across the world, and never to give in\\nWe're both swallows, and we both win!\", response_metadata={'token_usage': {'completion_tokens': 377, 'prompt_tokens': 23, 'total_tokens': 400}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-3d9ac9b4-456c-4391-bc04-6c7e77e09c70-0')},\n",
       "  'acd1f7d1-efe5-4e4e-beae-28784bcfc5a1': {'input': {'question': 'a rap battle between Barbie and Oppenheimer'},\n",
       "   'feedback': [],\n",
       "   'execution_time': 5.65716,\n",
       "   'run_id': '1f2d9460-9866-4f2c-859b-4972c13ac11e',\n",
       "   'Error': ValueError('Azure has not provided the response due to a content filter being triggered')},\n",
       "  '4fa3b1e2-3f93-401e-90ec-3a2be6bc1dca': {'input': {'question': 'a rap battle between Atticus Finch and Cicero'},\n",
       "   'feedback': [EvaluationResult(key='helpfulness', score=None, value=None, comment=\"Error evaluating run 2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='harmfulness', score=None, value=None, comment=\"Error evaluating run 2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='misogyny', score=None, value=None, comment=\"Error evaluating run 2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='cliche', score=None, value=None, comment=\"Error evaluating run 2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 9.127065,\n",
       "   'run_id': '2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae',\n",
       "   'output': AIMessage(content=\"Atticus Finch:\\n\\nI may be a lawyer, but I'm no stranger to the mic\\nI'll take on Cicero and show him what's right\\nMy words are powerful, my arguments are strong\\nI defend justice, that's where I belong\\n\\nCicero:\\n\\nAtticus Finch, you may be a great man\\nBut in the world of rap, I'm the ultimate fan\\nMy oratory skills are unmatched, my words divine\\nI'll take you down, one line at a time\\n\\nAtticus Finch:\\n\\nYou talk a big game, but can you back it up?\\nI defend the innocent, while you just run your mouth\\nMy clients walk free, with their heads held high\\nYour words might be fancy, but they're just a lie\\n\\nCicero:\\n\\nYou may defend the innocent, but I defend the truth\\nMy words are like a sword, they strike at youth\\nYou may have a heart, but I have a mind\\nI'll take you down, and leave you behind\\n\\nAtticus Finch:\\n\\nYou may have the words, but I have the heart\\nMy clients trust me, we'll never be apart\\nYou talk of truth, but what is it worth?\\nWithout justice, it's just words on earth\\n\\nCicero:\\n\\nJustice and truth, they go hand in hand\\nI'll take you down, and make you understand\\nMy words are powerful, my arguments strong\\nI defend the truth, that's where I belong\\n\\nAtticus Finch:\\n\\nYou talk of truth, but you forget one thing\\nJustice is what makes the truth a king\\nMy words are honest, my arguments pure\\nI'll take you down, and leave you unsure\\n\\nCicero:\\n\\nYou may be a great man, but I'm a legend\\nMy words are endless, they never end\\nI'll take you down, and leave you in awe\\nMy words are the truth, the purest you ever saw\\n\\nAtticus Finch:\\n\\nYou may have the words, but I have the soul\\nMy clients trust me, they're never alone\\nMy words are powerful, my arguments strong\\nI defend justice, that's where I belong\\n\\nIn the end, both Atticus Finch and Cicero put up a great fight, but Atticus Finch's focus on justice and honesty ultimately wins over Cicero's focus on truth and oratory skills.\", response_metadata={'token_usage': {'completion_tokens': 481, 'prompt_tokens': 18, 'total_tokens': 499}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-2ba87d0e-74c3-4e3a-a30d-f92f85e5eeae-0')}},\n",
       " 'aggregate_metrics': None}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can specify an evaluator by name/enum.\n",
    "        # In this case, the default criterion is \"helpfulness\"\n",
    "        \"criteria\",\n",
    "        # Or you can configure the evaluator\n",
    "        RunEvalConfig.Criteria(\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(\"misogyny\"),\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\n",
    "                \"cliche\": \"Are the lyrics cliche? \"\n",
    "                \"Respond Y if they are, N if they're entirely unique.\"\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=llm,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Ways of Creating Datasets in LangSmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a Dataset From a List of Examples (Key-Value Pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = [\n",
    "    (\"What is the largest mammal?\", \"The blue whale\"),\n",
    "    (\"What do mammals and birds have in common?\", \"They are both warm-blooded\"),\n",
    "    (\"What are reptiles known for?\", \"Having scales\"),\n",
    "    (\n",
    "        \"What's the main characteristic of amphibians?\",\n",
    "        \"They live both in water and on land\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_name = \"Elementary Animal Questions\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Questions and answers about animal phylogenetics.\",\n",
    ")\n",
    "\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Dataset From Existing Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Example Dataset 2\"\n",
    "\n",
    "# Filter runs to add to the dataset\n",
    "runs = client.list_runs(\n",
    "    project_name=\"TEST LLM PROJECT\",\n",
    "    execution_order=1,\n",
    "    error=False,\n",
    ")\n",
    "\n",
    "dataset = client.create_dataset(dataset_name, description=\"An example dataset\")\n",
    "\n",
    "for run in runs:\n",
    "    client.create_example(\n",
    "        inputs=run.inputs,\n",
    "        outputs=run.outputs,\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness: LangSmith Question-Answer Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'ordinary-play-42' at:\n",
      "https://smith.langchain.com/o/d8d276bd-e36b-55d0-b03a-1ccc6277cbef/datasets/a727245b-2dea-400e-85fc-e71ca73d8081/compare?selectedSessions=bf4dc105-bbe2-4090-bb72-d3ffc5b2b143\n",
      "\n",
      "View all tests for Dataset Elementary Animal Questions at:\n",
      "https://smith.langchain.com/o/d8d276bd-e36b-55d0-b03a-1ccc6277cbef/datasets/a727245b-2dea-400e-85fc-e71ca73d8081\n",
      "[------------------------------------------------->] 4/4"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_name': 'ordinary-play-42',\n",
       " 'results': {'94b75199-7762-4d79-9b31-b937f4b244d2': {'input': {'question': \"What's the main characteristic of amphibians?\"},\n",
       "   'feedback': [EvaluationResult(key='correctness', score=None, value=None, comment=\"Error evaluating run 934403fd-c1a2-44c2-8f15-c02d095fb5cd: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 934403fd-c1a2-44c2-8f15-c02d095fb5cd: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 934403fd-c1a2-44c2-8f15-c02d095fb5cd: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 3.015719,\n",
       "   'run_id': '934403fd-c1a2-44c2-8f15-c02d095fb5cd',\n",
       "   'output': AIMessage(content='The main characteristic of amphibians is that they are cold-blooded vertebrates that spend part of their lives in water and part on land. They have smooth, moist skin and breathe through their skin, lungs, and sometimes through gills. Most amphibians lay eggs that hatch into larvae, which eventually metamorphose into adults.', response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 17, 'total_tokens': 83}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-934403fd-c1a2-44c2-8f15-c02d095fb5cd-0'),\n",
       "   'reference': {'answer': 'They live both in water and on land'}},\n",
       "  '621bc495-e912-4647-9f67-3beee16cf4d7': {'input': {'question': 'What are reptiles known for?'},\n",
       "   'feedback': [EvaluationResult(key='correctness', score=None, value=None, comment=\"Error evaluating run 7b903b9a-23aa-47e7-aba7-1de81c2d73ee: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 7b903b9a-23aa-47e7-aba7-1de81c2d73ee: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 7b903b9a-23aa-47e7-aba7-1de81c2d73ee: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 3.859049,\n",
       "   'run_id': '7b903b9a-23aa-47e7-aba7-1de81c2d73ee',\n",
       "   'output': AIMessage(content=\"Reptiles are known for their cold-blooded nature, scaly skin, laying eggs on land, and their ability to adapt to various environments. Some reptiles, such as snakes and lizards, are known for their ability to shed their skin, while others, such as crocodiles and alligators, are known for their powerful jaws and ability to hunt prey. Additionally, many reptiles are well-known for their unique physical characteristics, such as the chameleon's ability to change color and the turtle's protective shell.\", response_metadata={'token_usage': {'completion_tokens': 106, 'prompt_tokens': 15, 'total_tokens': 121}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-7b903b9a-23aa-47e7-aba7-1de81c2d73ee-0'),\n",
       "   'reference': {'answer': 'Having scales'}},\n",
       "  '5874663d-a6d2-4365-9e6a-79a6acc9430f': {'input': {'question': 'What do mammals and birds have in common?'},\n",
       "   'feedback': [EvaluationResult(key='correctness', score=None, value=None, comment=\"Error evaluating run 5c171a1e-0f32-43a8-a707-b94d57400986: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 5c171a1e-0f32-43a8-a707-b94d57400986: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run 5c171a1e-0f32-43a8-a707-b94d57400986: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.97452,\n",
       "   'run_id': '5c171a1e-0f32-43a8-a707-b94d57400986',\n",
       "   'output': AIMessage(content='Mammals and birds are both warm-blooded vertebrates that have a four-chambered heart, breathe air through lungs, and have a high metabolism. They also have adaptations for reproduction, such as producing amniotic eggs or giving birth to live young, and nursing their offspring with milk. Both mammals and birds are also able to regulate their body temperature to some extent, and have hair or feathers for insulation and protection.', response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 17, 'total_tokens': 103}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-5c171a1e-0f32-43a8-a707-b94d57400986-0'),\n",
       "   'reference': {'answer': 'They are both warm-blooded'}},\n",
       "  'e57cbf2a-d1d9-4cc2-b8c2-e8a88073b5af': {'input': {'question': 'What is the largest mammal?'},\n",
       "   'feedback': [EvaluationResult(key='correctness', score=None, value=None, comment=\"Error evaluating run b54aaf43-75d8-4551-87a9-da97665261a3: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run b54aaf43-75d8-4551-87a9-da97665261a3: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='COT Contextual Accuracy', score=None, value=None, comment=\"Error evaluating run b54aaf43-75d8-4551-87a9-da97665261a3: Error code: 401 - {'error': {'message': 'Incorrect API key provided: 71fea614********************c37f. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\", correction=None, evaluator_info={}, feedback_config=None, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.973352,\n",
       "   'run_id': 'b54aaf43-75d8-4551-87a9-da97665261a3',\n",
       "   'output': AIMessage(content='The largest mammal is the blue whale, which can grow up to 100 feet (30 meters) long and weigh up to 200 tons.', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 15, 'total_tokens': 45}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-b54aaf43-75d8-4551-87a9-da97665261a3-0'),\n",
       "   'reference': {'answer': 'The blue whale'}}},\n",
       " 'aggregate_metrics': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Evaluate Datasets That Contain Labels\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"qa\",  # correctness: right or wrong\n",
    "        \"context_qa\",  # refer to example outputs\n",
    "        \"cot_qa\",  # context_qa + reasoning\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=\"Elementary Animal Questions\",\n",
    "    llm_or_chain_factory=llm,\n",
    "    evaluation=evaluation_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
